{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "great_pconv_test0131_OK",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orenodinner/PConv-Keras-for-google-colab/blob/master/4_google_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "H3wDd8rHbaPY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "アップロードコード"
      ]
    },
    {
      "metadata": {
        "id": "3PnFt1kkI3HA",
        "colab_type": "code",
        "outputId": "869b58ae-d22b-4248-d22a-5477dfc53a6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/orenodinner/PConv-Keras-for-google-colab.git\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PConv-Keras-for-google-colab'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 296 (delta 10), reused 0 (delta 0), pack-reused 277\u001b[K\n",
            "Receiving objects: 100% (296/296), 52.10 MiB | 24.73 MiB/s, done.\n",
            "Resolving deltas: 100% (143/143), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4dMo6I3cI_vV",
        "colab_type": "code",
        "outputId": "3403f9ba-b881-4dfa-f4fe-7490bb882135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd PConv-Keras-for-google-colab"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PConv-Keras-for-google-colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MLvln1aVUgjF",
        "colab_type": "code",
        "outputId": "5515afe8-95b2-4e60-b9ae-8535845b8455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import getpass\n",
        "auth.authenticate_user()\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 110851 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "51QmDZRiVSIM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "xxxxx.zipのようにzipで圧縮してGoogle Driveに普通にアップロードする。\n",
        "Colab上で以下を実行。/content/dataというディレクトリに大量データが展開される。\n",
        "ポイントは、> /dev/null 2>&1 &で、標準出力を捨てているところだ。\n",
        "\n",
        "そうしないと、unzipで大量データを展開したときに大量の標準出力が表示されてしまい、Chromeがクラッシュして落ちてしまうことがある。"
      ]
    },
    {
      "metadata": {
        "id": "qW6Ufxt3VRLw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir /content/PConv-Keras-for-google-colab/data_img/\n",
        "!mkdir /content/PConv-Keras-for-google-colab/data_img/images\n",
        "!unzip /content/PConv-Keras-for-google-colab/drive/resize.zip  -d /content/PConv-Keras-for-google-colab/data_img/images > /dev/null 2>&1 &"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mKUVGQ-vVidz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "解凍後のファイル数を確認するには以下を実行する。"
      ]
    },
    {
      "metadata": {
        "id": "PBPzZ_9OVmvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba0bfe7e-98bc-4605-f25a-31862c16f1da"
      },
      "cell_type": "code",
      "source": [
        "!echo ./data_img/images/* | xargs ls | wc"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   1094    1094   29538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BjUZ3Ud2JF5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b4d47284-d9b8-488b-d3f4-04f0816232dc"
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import NullFormatter\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from libs.pconv_model import PConvUnet\n",
        "from libs.util import random_mask\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "plt.ioff()\n",
        "\n",
        "# SETTINGS\n",
        "TRAIN_DIR = r\"./data_img/\"  #要編集\n",
        "TEST_DIR = r\"./data_img/\"\n",
        "VAL_DIR = r\"./data_img/\"\n",
        "\n",
        "BATCH_SIZE = 4"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GbZVactZpv7t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "5_8_mPSUSttU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# SETTINGS\n",
        "TRAIN_DIR = r\"./data_img/\"  #要編集\n",
        "TEST_DIR = r\"./data_img/\"\n",
        "VAL_DIR = r\"./data_img/\"\n",
        "\n",
        "BATCH_SIZE = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sx3Uw2RHJhHC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataGenerator(ImageDataGenerator):\n",
        "    def flow_from_directory(self, directory, *args, **kwargs):\n",
        "        generator = super().flow_from_directory(directory, class_mode=None, *args, **kwargs)\n",
        "        while True:\n",
        "            \n",
        "            # Get augmentend image samples\n",
        "            ori = next(generator)\n",
        "\n",
        "            # Get masks for each image sample\n",
        "            mask = np.stack([random_mask(ori.shape[1], ori.shape[2]) for _ in range(ori.shape[0])], axis=0)\n",
        "\n",
        "            # Apply masks to all image sample\n",
        "            masked = deepcopy(ori)\n",
        "            masked[mask==0] = 1\n",
        "\n",
        "            # Yield ([ori, masl],  ori) training batches\n",
        "            # print(masked.shape, ori.shape)\n",
        "            gc.collect()\n",
        "            yield [masked, mask], ori\n",
        "            \n",
        "# Create training generator\n",
        "train_datagen = DataGenerator(  \n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR, target_size=(512, 512), batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Create validation generator\n",
        "val_datagen = DataGenerator(rescale=1./255)\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    VAL_DIR, target_size=(512, 512), batch_size=BATCH_SIZE, seed=1\n",
        ")\n",
        "\n",
        "# Create testing generator\n",
        "test_datagen = DataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    TEST_DIR, target_size=(512, 512), batch_size=BATCH_SIZE, seed=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1QVP_ZXaJinX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "074a2463-0e00-49a2-d23d-584f38ed8d5a"
      },
      "cell_type": "code",
      "source": [
        "# Pick out an example\n",
        "test_data = next(test_generator)\n",
        "(masked, mask), ori = test_data\n",
        "\n",
        "# Show side by side\n",
        "for i in range(len(ori)):\n",
        "    _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "    axes[0].imshow(masked[i,:,:,:])\n",
        "    axes[1].imshow(mask[i,:,:,:] * 1.)\n",
        "    axes[2].imshow(ori[i,:,:,:])\n",
        "    #plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1094 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KirxVVNrJqe2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_callback(model):\n",
        "    \"\"\"Called at the end of each epoch, displaying our previous test images,\n",
        "    as well as their masked predictions and saving them to disk\"\"\"\n",
        "    \n",
        "    # Get samples & Display them        \n",
        "    pred_img = model.predict([masked, mask])\n",
        "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
        "\n",
        "    # Clear current output and display test images\n",
        "    for i in range(len(ori)):\n",
        "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "        axes[0].imshow(masked[i,:,:,:])\n",
        "        axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
        "        axes[2].imshow(ori[i,:,:,:])\n",
        "        axes[0].set_title('Masked Image')\n",
        "        axes[1].set_title('Predicted Image')\n",
        "        axes[2].set_title('Original Image')\n",
        "                \n",
        "        plt.savefig(r\"./data/img_{}_{}.png\".format(i, pred_time))\n",
        "        plt.close()\n",
        "        #plt.show()#ore追記"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5WlYH3bnK1UP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = PConvUnet(weight_filepath='./data/logs/')\n",
        "# model.load(r\"./data/logs/50_weights_2018-06-01-16-41-43.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bnWT9yy-N1i4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "eb935775-4cd0-4977-9fb7-49ebd28d6e2a"
      },
      "cell_type": "code",
      "source": [
        "# Run training for certain amount of epochs\n",
        "model.fit(\n",
        "    train_generator, \n",
        "    steps_per_epoch=1000,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=100,\n",
        "    epochs=50,        \n",
        "    plot_callback=plot_callback,\n",
        "    callbacks=[\n",
        "        TensorBoard(log_dir='./data/logs/initial_training', write_graph=False)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " 650/1000 [==================>...........] - ETA: 14:31 - loss: 920597.0121"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jEO-NmYgOGLE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load weights from previous run\n",
        "model = PConvUnet(weight_filepath='data/logs/')\n",
        "model.load(\n",
        "    r\"./data/logs/50_weights_2019-01-31-02-35-12.h5\", #修正必要\n",
        "    train_bn=False,\n",
        "    lr=0.00005\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Rw3D-TCOdti",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run training for certain amount of epochs\n",
        "model.fit(\n",
        "    train_generator, \n",
        "    steps_per_epoch=10,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=10,\n",
        "    epochs=50,        \n",
        "    workers=3,\n",
        "    plot_callback=plot_callback,\n",
        "    callbacks=[\n",
        "        TensorBoard(log_dir='./data/logs/fine_tuning', write_graph=False)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dHAXlEctOk8Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "リザルト"
      ]
    },
    {
      "metadata": {
        "id": "A5kIWDFTOoNK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load weights from previous run\n",
        "model = PConvUnet(weight_filepath='./data/logs/')\n",
        "model.load(\n",
        "    r\"./data/logs/50_weights_2019-01-31-02-35-12.h5\",\n",
        "    train_bn=False,\n",
        "    lr=0.00005\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L-yrEcbmBy7c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mkdir ./kekka_jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IE_aAoF3O5Ut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n = 0\n",
        "for (masked, mask), ori in tqdm(test_generator):\n",
        "    \n",
        "    # Run predictions for this batch of images\n",
        "    pred_img = model.predict([masked, mask])\n",
        "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
        "    \n",
        "    # Clear current output and display test images\n",
        "    for i in range(len(ori)):\n",
        "        _, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "        axes[0].imshow(masked[i,:,:,:])\n",
        "        axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
        "        axes[0].set_title('Masked Image')\n",
        "        axes[1].set_title('Predicted Image')\n",
        "        axes[0].xaxis.set_major_formatter(NullFormatter())\n",
        "        axes[0].yaxis.set_major_formatter(NullFormatter())\n",
        "        axes[1].xaxis.set_major_formatter(NullFormatter())\n",
        "        axes[1].yaxis.set_major_formatter(NullFormatter())\n",
        "                \n",
        "        plt.savefig(r'./kekka_jpg/img_{}_{}.png'.format(i, pred_time))\n",
        "        plt.close()\n",
        "       # plt.show()\n",
        "        n += 1\n",
        "        \n",
        "    # Only create predictions for about 100 images\n",
        "    if n > 100:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}